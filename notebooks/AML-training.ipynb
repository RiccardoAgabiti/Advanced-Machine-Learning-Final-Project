{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"### links used:\n# for the whole setup:       https://huggingface.co/docs/transformers/tasks/semantic_segmentation#preprocess\n# for criss cross attention: https://mmcv.readthedocs.io/en/latest/_modules/mmcv/ops/cc_attention.html\n# segofrmer source code:     https://github.com/huggingface/transformers/blob/v4.25.1/src/transformers/models/segformer/modeling_segformer.py#L746","metadata":{"id":"_2mV6-uzGMQg","execution":{"iopub.status.busy":"2022-12-23T12:00:17.349070Z","iopub.execute_input":"2022-12-23T12:00:17.349513Z","iopub.status.idle":"2022-12-23T12:00:17.354644Z","shell.execute_reply.started":"2022-12-23T12:00:17.349478Z","shell.execute_reply":"2022-12-23T12:00:17.353627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DATA LOADING & MANIPULATION","metadata":{"id":"2VTGmcjrdJ3M"}},{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom torch import nn\nimport json\nimport torchvision.transforms as T\nfrom functools import reduce\nfrom typing import Union\nimport math\nimport torch.nn.functional as F\nimport pickle\nimport os\nimport psutil\nimport shutil","metadata":{"id":"i_hWEKS_Pp3c","execution":{"iopub.status.busy":"2022-12-24T09:54:41.230985Z","iopub.execute_input":"2022-12-24T09:54:41.231400Z","iopub.status.idle":"2022-12-24T09:54:43.426030Z","shell.execute_reply.started":"2022-12-24T09:54:41.231368Z","shell.execute_reply":"2022-12-24T09:54:43.424400Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -q wandb","metadata":{"execution":{"iopub.status.busy":"2022-12-24T09:54:43.429265Z","iopub.execute_input":"2022-12-24T09:54:43.429639Z","iopub.status.idle":"2022-12-24T09:54:56.698065Z","shell.execute_reply.started":"2022-12-24T09:54:43.429587Z","shell.execute_reply":"2022-12-24T09:54:56.696890Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import wandb\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value = user_secrets.get_secret(\"wandb\")","metadata":{"execution":{"iopub.status.busy":"2022-12-24T09:54:56.699865Z","iopub.execute_input":"2022-12-24T09:54:56.700276Z","iopub.status.idle":"2022-12-24T09:54:57.546963Z","shell.execute_reply.started":"2022-12-24T09:54:56.700233Z","shell.execute_reply":"2022-12-24T09:54:57.545795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.environ[\"WANDB_API_KEY\"] = secret_value\n!wandb login","metadata":{"execution":{"iopub.status.busy":"2022-12-24T09:54:57.549814Z","iopub.execute_input":"2022-12-24T09:54:57.550232Z","iopub.status.idle":"2022-12-24T09:55:00.116641Z","shell.execute_reply.started":"2022-12-24T09:54:57.550193Z","shell.execute_reply":"2022-12-24T09:55:00.115441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -q datasets transformers evaluate pynvml accelerate","metadata":{"id":"jiFKQeufdrhm","outputId":"d706a8ec-3ce5-4920-fa9c-cc1ded699e27","execution":{"iopub.status.busy":"2022-12-23T12:00:26.816251Z","iopub.execute_input":"2022-12-23T12:00:26.817040Z","iopub.status.idle":"2022-12-23T12:00:37.290784Z","shell.execute_reply.started":"2022-12-23T12:00:26.817005Z","shell.execute_reply":"2022-12-23T12:00:37.289624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import hf_hub_download\nfrom pynvml import *\nfrom datasets import load_dataset, load_from_disk\nimport evaluate\nfrom transformers import SegformerFeatureExtractor\nfrom transformers import TrainingArguments, Trainer, logging\nfrom transformers import AutoModelForSemanticSegmentation\nfrom transformers import SegformerForSemanticSegmentation, SegformerConfig","metadata":{"id":"N9aG8sflmcas","execution":{"iopub.status.busy":"2022-12-23T12:00:37.292354Z","iopub.execute_input":"2022-12-23T12:00:37.293096Z","iopub.status.idle":"2022-12-23T12:00:44.604759Z","shell.execute_reply.started":"2022-12-23T12:00:37.293048Z","shell.execute_reply":"2022-12-23T12:00:44.603751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def print_gpu_utilization():\n    nvmlInit()\n    handle = nvmlDeviceGetHandleByIndex(0)\n    info = nvmlDeviceGetMemoryInfo(handle)\n    print(f\"GPU memory occupied: {info.used//1024**2} MB.\")\n\n\ndef print_summary(result):\n  \n    print(f\"Time: {result.metrics['train_runtime']:.2f}\")\n    print(f\"Samples/second: {result.metrics['train_samples_per_second']:.2f}\")\n    print_gpu_utilization()","metadata":{"id":"NeLeRLfvhGdm","execution":{"iopub.status.busy":"2022-12-23T12:00:44.606039Z","iopub.execute_input":"2022-12-23T12:00:44.606819Z","iopub.status.idle":"2022-12-23T12:00:44.612125Z","shell.execute_reply.started":"2022-12-23T12:00:44.606784Z","shell.execute_reply":"2022-12-23T12:00:44.611218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print_gpu_utilization()","metadata":{"id":"y2qlDmBMhIDj","outputId":"bc15dbe9-4b05-4583-93c2-f8712ce6985d","execution":{"iopub.status.busy":"2022-12-23T12:00:44.613828Z","iopub.execute_input":"2022-12-23T12:00:44.614216Z","iopub.status.idle":"2022-12-23T12:00:44.655084Z","shell.execute_reply.started":"2022-12-23T12:00:44.614177Z","shell.execute_reply":"2022-12-23T12:00:44.654084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ds = load_dataset(\"scene_parse_150\")","metadata":{"id":"G02mwcufeYo8","outputId":"feeb5734-c104-4b6d-c17d-955ff38bb7bd","execution":{"iopub.status.busy":"2022-12-23T12:00:44.656603Z","iopub.execute_input":"2022-12-23T12:00:44.657084Z","iopub.status.idle":"2022-12-23T12:01:28.565096Z","shell.execute_reply.started":"2022-12-23T12:00:44.657033Z","shell.execute_reply":"2022-12-23T12:01:28.563962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"repo_id = \"huggingface/label-files\"\nfilename = \"ade20k-id2label.json\"\nid2label = json.load(open(hf_hub_download(repo_id, filename, repo_type=\"dataset\"), \"r\"))\nid2label = {int(k):v for k,v in id2label.items()}\n\nlabel2id = {v: k for k, v in id2label.items()}\nnum_labels = len(id2label)","metadata":{"id":"JYSkLQYl6qVY","outputId":"b5a22e1f-a6d6-4dfb-b326-c9e4ef007925","execution":{"iopub.status.busy":"2022-12-23T12:01:28.569871Z","iopub.execute_input":"2022-12-23T12:01:28.570273Z","iopub.status.idle":"2022-12-23T12:01:28.823595Z","shell.execute_reply.started":"2022-12-23T12:01:28.570234Z","shell.execute_reply":"2022-12-23T12:01:28.822610Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds=ds['train']#.train_test_split(test_size=0.996) #Using only a small portion of the dataset\n#train_ds = train_ds['train']\n\nvalidation_ds=ds['validation']#.train_test_split(test_size=0.996)\n#validation_ds = validation_ds['train']\n\ntest_ds=ds['test']#.train_test_split(test_size=0.996)\n#test_ds = test_ds['train']","metadata":{"id":"F8GVNMCm6QEP","execution":{"iopub.status.busy":"2022-12-23T12:01:28.825259Z","iopub.execute_input":"2022-12-23T12:01:28.825996Z","iopub.status.idle":"2022-12-23T12:01:29.166692Z","shell.execute_reply.started":"2022-12-23T12:01:28.825919Z","shell.execute_reply":"2022-12-23T12:01:29.165649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds,validation_ds,test_ds","metadata":{"id":"dQyBY9IYEUC3","outputId":"624671ac-d145-4071-b9c9-c18ab98661f6","execution":{"iopub.status.busy":"2022-12-23T12:01:29.170832Z","iopub.execute_input":"2022-12-23T12:01:29.171160Z","iopub.status.idle":"2022-12-23T12:01:29.181300Z","shell.execute_reply.started":"2022-12-23T12:01:29.171131Z","shell.execute_reply":"2022-12-23T12:01:29.180078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def remove_data(data, typee):\n  #drop data missing annotations and mask\n  data.set_format(type='pandas')\n  if typee=='train':\n    n=20210\n  elif typee=='test':\n    n=3352\n  else:\n    n=2000\n\n  m=np.array\n  indices=[]\n  for i in range(n):\n    if m(data[i]['image'][0]).shape[-1] != 3:\n      indices.append(i)\n\n  data.set_format(type='pytorch')\n\n  if len(indices)==0:\n    pass\n  else:\n    colored_indexes = list(range(len(data)))\n    for i in indices:\n      colored_indexes.remove(i)\n    data=data.select(colored_indexes)\n\n  return data\n\ntrain_ds = remove_data(train_ds, 'train')\nvalidation_ds = remove_data(validation_ds, 'validation')\ntest_ds = remove_data(test_ds, 'test')","metadata":{"id":"M9jr2WdwgFs9","execution":{"iopub.status.busy":"2022-12-23T12:01:29.182998Z","iopub.execute_input":"2022-12-23T12:01:29.183628Z","iopub.status.idle":"2022-12-23T12:04:47.309471Z","shell.execute_reply.started":"2022-12-23T12:01:29.183591Z","shell.execute_reply":"2022-12-23T12:04:47.308558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds, validation_ds, test_ds","metadata":{"id":"ftaWSERNGVw3","outputId":"2164bf52-13a3-4a37-ee7f-df6b5b49d713","execution":{"iopub.status.busy":"2022-12-23T12:04:47.310746Z","iopub.execute_input":"2022-12-23T12:04:47.311082Z","iopub.status.idle":"2022-12-23T12:04:47.320909Z","shell.execute_reply.started":"2022-12-23T12:04:47.311048Z","shell.execute_reply":"2022-12-23T12:04:47.319892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_transforms(example_batch):\n  #qui possiamo randomizzare procedura di augmentation data\n    transforms = T.RandomApply(\n        [T.RandomHorizontalFlip(p=1),\n         T.RandomInvert(),\n         T.Grayscale(num_output_channels=3),\n         T.GaussianBlur(9, sigma=0.1),\n         T.RandomResizedCrop(512,scale=(0.5, 2.0)),\n         T.RandomResizedCrop(1024,scale=(0.5, 2.0))\n        ], p=0.25)\n    \n    feature_extractor=SegformerFeatureExtractor()\n\n    images = [transforms(x) for x in example_batch[\"image\"]]\n    labels = [x for x in example_batch[\"annotation\"]]\n    inputs = feature_extractor(images, labels)\n    return inputs\n\n\ndef val_transforms(example_batch):\n    feature_extractor=SegformerFeatureExtractor()\n\n    images = [x for x in example_batch[\"image\"]]\n    labels = [x for x in example_batch[\"annotation\"]]\n    inputs = feature_extractor(images, labels)\n    return inputs","metadata":{"id":"qWNTNqWpfUj1","execution":{"iopub.status.busy":"2022-12-23T12:04:47.322585Z","iopub.execute_input":"2022-12-23T12:04:47.323035Z","iopub.status.idle":"2022-12-23T12:04:47.333326Z","shell.execute_reply.started":"2022-12-23T12:04:47.323001Z","shell.execute_reply":"2022-12-23T12:04:47.332416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds.set_transform(train_transforms)\ntest_ds.set_transform(val_transforms)\nvalidation_ds.set_transform(val_transforms)","metadata":{"id":"j7jms0Wzfl8L","execution":{"iopub.status.busy":"2022-12-23T12:04:47.334535Z","iopub.execute_input":"2022-12-23T12:04:47.334962Z","iopub.status.idle":"2022-12-23T12:04:47.346617Z","shell.execute_reply.started":"2022-12-23T12:04:47.334927Z","shell.execute_reply":"2022-12-23T12:04:47.345797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#print_gpu_utilization()","metadata":{"id":"tYXcLpmohoPQ","execution":{"iopub.status.busy":"2022-12-23T12:04:47.347867Z","iopub.execute_input":"2022-12-23T12:04:47.348261Z","iopub.status.idle":"2022-12-23T12:04:47.357349Z","shell.execute_reply.started":"2022-12-23T12:04:47.348226Z","shell.execute_reply":"2022-12-23T12:04:47.356426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Look at augmentation\nimport matplotlib.pyplot as plt\nimg=torch.tensor(train_ds[3]['pixel_values'][:])\nimg=torch.permute(img, (1,2,0))\nplt.imshow(img)","metadata":{"id":"4o_iyLu_oJKY","outputId":"28ab45b0-2afe-4eae-db01-c20bd78dad27","execution":{"iopub.status.busy":"2022-12-23T12:04:47.358906Z","iopub.execute_input":"2022-12-23T12:04:47.359243Z","iopub.status.idle":"2022-12-23T12:04:47.670909Z","shell.execute_reply.started":"2022-12-23T12:04:47.359209Z","shell.execute_reply":"2022-12-23T12:04:47.669939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ATTENTION","metadata":{"id":"heiZtAaSJu7w"}},{"cell_type":"markdown","source":"## dito nel culo: criss cross","metadata":{"id":"1hb7ikpEOcyx"}},{"cell_type":"code","source":"def NEG_INF_DIAG(n: int, device: torch.device) -> torch.Tensor:\n    \"\"\"Returns a diagonal matrix of size [n, n].\n\n    The diagonal are all \"-inf\". This is for avoiding calculating the\n    overlapped element in the Criss-Cross twice.\n    \"\"\"\n    return torch.diag(torch.tensor(float('-inf')).to(device).repeat(n), 0)\n\n\nclass Scale(nn.Module):\n    \"\"\"A learnable scale parameter.\n\n    This layer scales the input by a learnable factor. It multiplies a\n    learnable scale parameter of shape (1,) with input of any shape.\n\n    Args:\n        scale (float): Initial value of scale factor. Default: 1.0\n    \"\"\"\n\n    def __init__(self, scale: float = 1.0):\n        super().__init__()\n        self.scale = nn.Parameter(torch.tensor(scale, dtype=torch.float))\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        return x * self.scale\n\n\nclass CrissCrossAttention(nn.Module):\n    \"\"\"Criss-Cross Attention Module.\n\n    .. note::\n        Before v1.3.13, we use a CUDA op. Since v1.3.13, we switch\n        to a pure PyTorch and equivalent implementation. For more\n        details, please refer to https://github.com/open-mmlab/mmcv/pull/1201.\n\n        Speed comparison for one forward pass\n\n        - Input size: [2,512,97,97]\n        - Device: 1 NVIDIA GeForce RTX 2080 Ti\n\n        +-----------------------+---------------+------------+---------------+\n        |                       |PyTorch version|CUDA version|Relative speed |\n        +=======================+===============+============+===============+\n        |with torch.no_grad()   |0.00554402 s   |0.0299619 s |5.4x           |\n        +-----------------------+---------------+------------+---------------+\n        |no with torch.no_grad()|0.00562803 s   |0.0301349 s |5.4x           |\n        +-----------------------+---------------+------------+---------------+\n\n    Args:\n        in_channels (int): Channels of the input feature map.\n    \"\"\"\n\n    def __init__(self, in_channels: int) -> None:\n        super().__init__()\n        self.query_conv = nn.Conv2d(in_channels, in_channels // 8, 1)\n        self.key_conv = nn.Conv2d(in_channels, in_channels // 8, 1)\n        self.value_conv = nn.Conv2d(in_channels, in_channels, 1)\n        self.gamma = Scale(0.)\n        self.in_channels = in_channels\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"forward function of Criss-Cross Attention.\n\n        Args:\n            x (torch.Tensor): Input feature with the shape of\n                (batch_size, in_channels, height, width).\n\n        Returns:\n            torch.Tensor: Output of the layer, with the shape of\n            (batch_size, in_channels, height, width)\n        \"\"\"\n        B, C, H, W = x.size()\n        query = self.query_conv(x)\n        key = self.key_conv(x)\n        value = self.value_conv(x)\n        energy_H = torch.einsum('bchw,bciw->bwhi', query, key) + NEG_INF_DIAG(\n            H, query.device)\n        energy_H = energy_H.transpose(1, 2)\n        energy_W = torch.einsum('bchw,bchj->bhwj', query, key)\n        attn = F.softmax(\n            torch.cat([energy_H, energy_W], dim=-1), dim=-1)  # [B,H,W,(H+W)]\n        out = torch.einsum('bciw,bhwi->bchw', value, attn[..., :H])\n        out += torch.einsum('bchj,bhwj->bchw', value, attn[..., H:])\n\n        out = self.gamma(out) + x\n        out = out.contiguous()\n\n        return out\n\n\n    def __repr__(self) -> str:\n        s = self.__class__.__name__\n        s += f'(in_channels={self.in_channels})'\n        return s","metadata":{"id":"oS-y0S0qqKum","execution":{"iopub.status.busy":"2022-12-23T12:04:47.671950Z","iopub.execute_input":"2022-12-23T12:04:47.672290Z","iopub.status.idle":"2022-12-23T12:04:47.688091Z","shell.execute_reply.started":"2022-12-23T12:04:47.672254Z","shell.execute_reply":"2022-12-23T12:04:47.686956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MySegformerAttention(nn.Module):\n    def __init__(self, config, hidden_size):\n        super().__init__()\n        self.cca = CrissCrossAttention(hidden_size)\n        \n\n\n    def forward(self, hidden_states, height, width, output_attentions=False):\n       \n        #self_outputs = self.self(hidden_states, height, width, output_attentions)\n        #context_layer = self_outputs[0] # (1,16384,32) = (1,height*width,hidden_states.shape[-1] )\n\n        x=torch.reshape(hidden_states, (hidden_states.shape[0],hidden_states.shape[-1], height, width))\n        self_outputs= self.cca(x)\n        self_outputs=torch.reshape(self_outputs, (hidden_states.shape[0], height*width, hidden_states.shape[-1]))\n        self_outputs=(self_outputs,)\n\n\n        #attention_output = self.output(self_outputs[0], hidden_states) # (1,16384,32)\n        #outputs = (attention_output,) + self_outputs[1:]  # add attentions if we output them\n        #print('outputs: ', (outputs[0].shape)) (1,16384,32)\n       \n        return self_outputs\n","metadata":{"id":"BXCW1WGlJ86t","execution":{"iopub.status.busy":"2022-12-23T12:04:47.689748Z","iopub.execute_input":"2022-12-23T12:04:47.690114Z","iopub.status.idle":"2022-12-23T12:04:47.701306Z","shell.execute_reply.started":"2022-12-23T12:04:47.690068Z","shell.execute_reply":"2022-12-23T12:04:47.700456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## sostituisci layer col nostro","metadata":{"id":"TK7XyPleOZLW"}},{"cell_type":"code","source":"#RUN THIS CELL ONLY IF RUNNING FIRST EPOCH OF TRAINING, TO INITIALIZE THE MODEL,\n#IF WANT TO LOAD MODEL FROM SAVED STATE USE NEXT CELL\n\n#pretrained_model_name = \"nvidia/mit-b0\"\n#model = AutoModelForSemanticSegmentation.from_pretrained(pretrained_model_name)\n#config=model.config\n#\n#\n##aggiorneremo i pesi solo dei nuovi layer\n#for param in model.parameters(): \n#    param.requires_grad = False\n#\n#\n#def replace_att_layers(model):\n#  #replace attention layers with our attention layer\n#  sizes=[32,32,64,64,160,160,256,256]\n#  counter=0\n#\n#  for module in model.modules():\n#    classname = module.__class__.__name__\n#\n#    if 'SegformerLayer' in classname:\n#      module.attention=MySegformerAttention(config, sizes[counter])\n#      counter+=1\n#\n#  return model\n#\n#model=replace_att_layers(model)\n#\n#for param in model.decode_head.parameters():\n#  param.requires_grad = True","metadata":{"id":"Trg4n1RzCxrt","outputId":"b5899cbd-2f81-47ca-9948-cfb1e616c61e","execution":{"iopub.status.busy":"2022-12-23T12:04:47.702951Z","iopub.execute_input":"2022-12-23T12:04:47.703366Z","iopub.status.idle":"2022-12-23T12:04:48.539488Z","shell.execute_reply.started":"2022-12-23T12:04:47.703330Z","shell.execute_reply":"2022-12-23T12:04:48.538613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir '/kaggle/working/AML/'\n!mkdir '/kaggle/working/AML/models/'\n!mkdir '/kaggle/working/AML/models/very_final_train/'","metadata":{"execution":{"iopub.status.busy":"2022-12-23T12:04:48.540855Z","iopub.execute_input":"2022-12-23T12:04:48.541292Z","iopub.status.idle":"2022-12-23T12:04:51.470851Z","shell.execute_reply.started":"2022-12-23T12:04:48.541256Z","shell.execute_reply":"2022-12-23T12:04:51.469511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# TRAINING","metadata":{"id":"jYYmvEwXcD9n"}},{"cell_type":"code","source":"#IN B0-FINAL TRAIN CI SO LE RUN CON LE LOSS IN TEORIA\n#IN FINAL TRAIN IL MODELLO CON I PARAMETRI PER EPOCH","metadata":{"id":"je6fkqEKdZ5s","execution":{"iopub.status.busy":"2022-12-23T12:04:51.473135Z","iopub.execute_input":"2022-12-23T12:04:51.473560Z","iopub.status.idle":"2022-12-23T12:04:51.478307Z","shell.execute_reply.started":"2022-12-23T12:04:51.473521Z","shell.execute_reply":"2022-12-23T12:04:51.477223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#LOAD MODEL FROM EPOCH\n#from_epoch='epoch3' \n#path='/content/drive/MyDrive/AML/models/final_train/'\n#model=torch.load(path+from_epoch)","metadata":{"id":"UUA4gDzHav2S","execution":{"iopub.status.busy":"2022-12-23T12:04:51.479807Z","iopub.execute_input":"2022-12-23T12:04:51.480890Z","iopub.status.idle":"2022-12-23T12:04:51.494231Z","shell.execute_reply.started":"2022-12-23T12:04:51.480844Z","shell.execute_reply":"2022-12-23T12:04:51.493159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metric = evaluate.load(\"mean_iou\")","metadata":{"id":"nABUKFORfsY8","outputId":"db6bc021-3f53-4ea6-b6b0-b978706904ee","execution":{"iopub.status.busy":"2022-12-23T12:04:51.496298Z","iopub.execute_input":"2022-12-23T12:04:51.497438Z","iopub.status.idle":"2022-12-23T12:04:51.882904Z","shell.execute_reply.started":"2022-12-23T12:04:51.497381Z","shell.execute_reply":"2022-12-23T12:04:51.881858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_metrics(eval_pred):\n    with torch.no_grad():\n        logits, labels = eval_pred\n        logits_tensor = torch.from_numpy(logits)\n        logits_tensor = nn.functional.interpolate(\n            logits_tensor,\n            size=labels.shape[-2:],\n            mode=\"bilinear\",\n            align_corners=False,\n        ).argmax(dim=1)\n\n        pred_labels = logits_tensor.detach().cpu().numpy()\n        metrics = metric.compute(\n            predictions=pred_labels,\n            references=labels,\n            num_labels=num_labels,\n            ignore_index=255,\n            reduce_labels=False,\n        )\n        for key, value in metrics.items():\n            if type(value) is np.ndarray:\n                metrics[key] = value.tolist()\n        return metrics","metadata":{"id":"pzw6SLPWfxCB","execution":{"iopub.status.busy":"2022-12-23T12:04:51.884369Z","iopub.execute_input":"2022-12-23T12:04:51.884786Z","iopub.status.idle":"2022-12-23T12:04:51.894513Z","shell.execute_reply.started":"2022-12-23T12:04:51.884742Z","shell.execute_reply":"2022-12-23T12:04:51.893133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print_gpu_utilization()","metadata":{"id":"72GeQqPx__ne","outputId":"148abdcd-9583-4d53-9da5-4d89a87d5337","execution":{"iopub.status.busy":"2022-12-23T12:04:51.895932Z","iopub.execute_input":"2022-12-23T12:04:51.896520Z","iopub.status.idle":"2022-12-23T12:04:51.907743Z","shell.execute_reply.started":"2022-12-23T12:04:51.896485Z","shell.execute_reply":"2022-12-23T12:04:51.906634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#PER TRAIN SU KAGGLE ALMENO SALVIAMO A OGNI EPOCH\npath='/kaggle/working/AML/models/very_final_train/'\nfrom_epoch='epoch6' \nmodel=torch.load('/kaggle/input/epoch6/epoch6')\nfor i in range(4):\n    epochs=('epoch{}').format(int(from_epoch[5:])+i+1)\n    \n    training_args = TrainingArguments(\n    #auto_find_batch_size = True,\n    per_device_train_batch_size = 1,\n    per_device_eval_batch_size = 1,\n    gradient_accumulation_steps = 4,\n    evaluation_strategy = 'epoch',\n    eval_accumulation_steps=1, # MAY CHANGE IT\n    optim = 'adafactor',\n    output_dir=\"/kaggle/working/AML/models/b0_very_final_train/\"+epochs,\n    learning_rate=6e-5,\n    num_train_epochs=1,\n    save_strategy=\"epoch\",\n    #eval_steps=1,\n    remove_unused_columns=False,\n    debug = 'underflow_overflow',\n    prediction_loss_only = True, \n    log_level = 'critical',\n    logging_strategy = 'epoch',\n    #fp16_full_eval = True,\n    #dataloader_num_workers = 2\n    load_best_model_at_end = False\n    #, gradient_checkpointing = True\n    )\n    \n    trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_ds,\n    eval_dataset=validation_ds,\n    compute_metrics=compute_metrics\n    )\n\n    results = trainer.train() \n    torch.save(model, path+epochs)\n    print(('finished {}').format(epochs))","metadata":{"id":"LseWuIIZN4Dl","outputId":"ceb7c595-2433-4d94-de23-5b4517d6dffa","execution":{"iopub.status.busy":"2022-12-23T12:04:51.913631Z","iopub.execute_input":"2022-12-23T12:04:51.913908Z","iopub.status.idle":"2022-12-23T12:05:45.139145Z","shell.execute_reply.started":"2022-12-23T12:04:51.913884Z","shell.execute_reply":"2022-12-23T12:05:45.137466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shutil.make_archive('AML', 'zip', '/kaggle/working/AML/')","metadata":{"execution":{"iopub.status.busy":"2022-12-23T12:05:45.140437Z","iopub.status.idle":"2022-12-23T12:05:45.141316Z","shell.execute_reply.started":"2022-12-23T12:05:45.141045Z","shell.execute_reply":"2022-12-23T12:05:45.141072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"ccV4BhwsMiRD"},"execution_count":null,"outputs":[]}]}