{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-23T12:00:17.349513Z",
     "iopub.status.busy": "2022-12-23T12:00:17.349070Z",
     "iopub.status.idle": "2022-12-23T12:00:17.354644Z",
     "shell.execute_reply": "2022-12-23T12:00:17.353627Z",
     "shell.execute_reply.started": "2022-12-23T12:00:17.349478Z"
    },
    "id": "_2mV6-uzGMQg"
   },
   "outputs": [],
   "source": [
    "### links used:\n",
    "# for the whole setup:       https://huggingface.co/docs/transformers/tasks/semantic_segmentation#preprocess\n",
    "# for criss cross attention: https://mmcv.readthedocs.io/en/latest/_modules/mmcv/ops/cc_attention.html\n",
    "# segofrmer source code:     https://github.com/huggingface/transformers/blob/v4.25.1/src/transformers/models/segformer/modeling_segformer.py#L746"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2VTGmcjrdJ3M"
   },
   "source": [
    "# DATA LOADING & MANIPULATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-24T09:54:41.231400Z",
     "iopub.status.busy": "2022-12-24T09:54:41.230985Z",
     "iopub.status.idle": "2022-12-24T09:54:43.426030Z",
     "shell.execute_reply": "2022-12-24T09:54:43.424400Z",
     "shell.execute_reply.started": "2022-12-24T09:54:41.231368Z"
    },
    "id": "i_hWEKS_Pp3c"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import json\n",
    "import torchvision.transforms as T\n",
    "from functools import reduce\n",
    "from typing import Union\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "import os\n",
    "import psutil\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-24T09:54:43.429639Z",
     "iopub.status.busy": "2022-12-24T09:54:43.429265Z",
     "iopub.status.idle": "2022-12-24T09:54:56.698065Z",
     "shell.execute_reply": "2022-12-24T09:54:56.696890Z",
     "shell.execute_reply.started": "2022-12-24T09:54:43.429587Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-24T09:54:56.700276Z",
     "iopub.status.busy": "2022-12-24T09:54:56.699865Z",
     "iopub.status.idle": "2022-12-24T09:54:57.546963Z",
     "shell.execute_reply": "2022-12-24T09:54:57.545795Z",
     "shell.execute_reply.started": "2022-12-24T09:54:56.700233Z"
    }
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "user_secrets = UserSecretsClient()\n",
    "secret_value = user_secrets.get_secret(\"wandb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-24T09:54:57.550232Z",
     "iopub.status.busy": "2022-12-24T09:54:57.549814Z",
     "iopub.status.idle": "2022-12-24T09:55:00.116641Z",
     "shell.execute_reply": "2022-12-24T09:55:00.115441Z",
     "shell.execute_reply.started": "2022-12-24T09:54:57.550193Z"
    }
   },
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_API_KEY\"] = secret_value\n",
    "!wandb login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-23T12:00:26.817040Z",
     "iopub.status.busy": "2022-12-23T12:00:26.816251Z",
     "iopub.status.idle": "2022-12-23T12:00:37.290784Z",
     "shell.execute_reply": "2022-12-23T12:00:37.289624Z",
     "shell.execute_reply.started": "2022-12-23T12:00:26.817005Z"
    },
    "id": "jiFKQeufdrhm",
    "outputId": "d706a8ec-3ce5-4920-fa9c-cc1ded699e27"
   },
   "outputs": [],
   "source": [
    "!pip install -q datasets transformers evaluate pynvml accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-23T12:00:37.293096Z",
     "iopub.status.busy": "2022-12-23T12:00:37.292354Z",
     "iopub.status.idle": "2022-12-23T12:00:44.604759Z",
     "shell.execute_reply": "2022-12-23T12:00:44.603751Z",
     "shell.execute_reply.started": "2022-12-23T12:00:37.293048Z"
    },
    "id": "N9aG8sflmcas"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "from pynvml import *\n",
    "from datasets import load_dataset, load_from_disk\n",
    "import evaluate\n",
    "from transformers import SegformerFeatureExtractor\n",
    "from transformers import TrainingArguments, Trainer, logging\n",
    "from transformers import AutoModelForSemanticSegmentation\n",
    "from transformers import SegformerForSemanticSegmentation, SegformerConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-23T12:00:44.606819Z",
     "iopub.status.busy": "2022-12-23T12:00:44.606039Z",
     "iopub.status.idle": "2022-12-23T12:00:44.612125Z",
     "shell.execute_reply": "2022-12-23T12:00:44.611218Z",
     "shell.execute_reply.started": "2022-12-23T12:00:44.606784Z"
    },
    "id": "NeLeRLfvhGdm"
   },
   "outputs": [],
   "source": [
    "def print_gpu_utilization():\n",
    "    nvmlInit()\n",
    "    handle = nvmlDeviceGetHandleByIndex(0)\n",
    "    info = nvmlDeviceGetMemoryInfo(handle)\n",
    "    print(f\"GPU memory occupied: {info.used//1024**2} MB.\")\n",
    "\n",
    "\n",
    "def print_summary(result):\n",
    "  \n",
    "    print(f\"Time: {result.metrics['train_runtime']:.2f}\")\n",
    "    print(f\"Samples/second: {result.metrics['train_samples_per_second']:.2f}\")\n",
    "    print_gpu_utilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-23T12:00:44.614216Z",
     "iopub.status.busy": "2022-12-23T12:00:44.613828Z",
     "iopub.status.idle": "2022-12-23T12:00:44.655084Z",
     "shell.execute_reply": "2022-12-23T12:00:44.654084Z",
     "shell.execute_reply.started": "2022-12-23T12:00:44.614177Z"
    },
    "id": "y2qlDmBMhIDj",
    "outputId": "bc15dbe9-4b05-4583-93c2-f8712ce6985d"
   },
   "outputs": [],
   "source": [
    "print_gpu_utilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-23T12:00:44.657084Z",
     "iopub.status.busy": "2022-12-23T12:00:44.656603Z",
     "iopub.status.idle": "2022-12-23T12:01:28.565096Z",
     "shell.execute_reply": "2022-12-23T12:01:28.563962Z",
     "shell.execute_reply.started": "2022-12-23T12:00:44.657033Z"
    },
    "id": "G02mwcufeYo8",
    "outputId": "feeb5734-c104-4b6d-c17d-955ff38bb7bd"
   },
   "outputs": [],
   "source": [
    "ds = load_dataset(\"scene_parse_150\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-23T12:01:28.570273Z",
     "iopub.status.busy": "2022-12-23T12:01:28.569871Z",
     "iopub.status.idle": "2022-12-23T12:01:28.823595Z",
     "shell.execute_reply": "2022-12-23T12:01:28.822610Z",
     "shell.execute_reply.started": "2022-12-23T12:01:28.570234Z"
    },
    "id": "JYSkLQYl6qVY",
    "outputId": "b5a22e1f-a6d6-4dfb-b326-c9e4ef007925"
   },
   "outputs": [],
   "source": [
    "repo_id = \"huggingface/label-files\"\n",
    "filename = \"ade20k-id2label.json\"\n",
    "id2label = json.load(open(hf_hub_download(repo_id, filename, repo_type=\"dataset\"), \"r\"))\n",
    "id2label = {int(k):v for k,v in id2label.items()}\n",
    "\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "num_labels = len(id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-23T12:01:28.825996Z",
     "iopub.status.busy": "2022-12-23T12:01:28.825259Z",
     "iopub.status.idle": "2022-12-23T12:01:29.166692Z",
     "shell.execute_reply": "2022-12-23T12:01:29.165649Z",
     "shell.execute_reply.started": "2022-12-23T12:01:28.825919Z"
    },
    "id": "F8GVNMCm6QEP"
   },
   "outputs": [],
   "source": [
    "train_ds=ds['train']#.train_test_split(test_size=0.996) #Using only a small portion of the dataset\n",
    "#train_ds = train_ds['train']\n",
    "\n",
    "validation_ds=ds['validation']#.train_test_split(test_size=0.996)\n",
    "#validation_ds = validation_ds['train']\n",
    "\n",
    "test_ds=ds['test']#.train_test_split(test_size=0.996)\n",
    "#test_ds = test_ds['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-23T12:01:29.171160Z",
     "iopub.status.busy": "2022-12-23T12:01:29.170832Z",
     "iopub.status.idle": "2022-12-23T12:01:29.181300Z",
     "shell.execute_reply": "2022-12-23T12:01:29.180078Z",
     "shell.execute_reply.started": "2022-12-23T12:01:29.171131Z"
    },
    "id": "dQyBY9IYEUC3",
    "outputId": "624671ac-d145-4071-b9c9-c18ab98661f6"
   },
   "outputs": [],
   "source": [
    "train_ds,validation_ds,test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-23T12:01:29.183628Z",
     "iopub.status.busy": "2022-12-23T12:01:29.182998Z",
     "iopub.status.idle": "2022-12-23T12:04:47.309471Z",
     "shell.execute_reply": "2022-12-23T12:04:47.308558Z",
     "shell.execute_reply.started": "2022-12-23T12:01:29.183591Z"
    },
    "id": "M9jr2WdwgFs9"
   },
   "outputs": [],
   "source": [
    "def remove_data(data, typee):\n",
    "  #drop data missing annotations and mask\n",
    "  data.set_format(type='pandas')\n",
    "  if typee=='train':\n",
    "    n=20210\n",
    "  elif typee=='test':\n",
    "    n=3352\n",
    "  else:\n",
    "    n=2000\n",
    "\n",
    "  m=np.array\n",
    "  indices=[]\n",
    "  for i in range(n):\n",
    "    if m(data[i]['image'][0]).shape[-1] != 3:\n",
    "      indices.append(i)\n",
    "\n",
    "  data.set_format(type='pytorch')\n",
    "\n",
    "  if len(indices)==0:\n",
    "    pass\n",
    "  else:\n",
    "    colored_indexes = list(range(len(data)))\n",
    "    for i in indices:\n",
    "      colored_indexes.remove(i)\n",
    "    data=data.select(colored_indexes)\n",
    "\n",
    "  return data\n",
    "\n",
    "train_ds = remove_data(train_ds, 'train')\n",
    "validation_ds = remove_data(validation_ds, 'validation')\n",
    "test_ds = remove_data(test_ds, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-23T12:04:47.311082Z",
     "iopub.status.busy": "2022-12-23T12:04:47.310746Z",
     "iopub.status.idle": "2022-12-23T12:04:47.320909Z",
     "shell.execute_reply": "2022-12-23T12:04:47.319892Z",
     "shell.execute_reply.started": "2022-12-23T12:04:47.311048Z"
    },
    "id": "ftaWSERNGVw3",
    "outputId": "2164bf52-13a3-4a37-ee7f-df6b5b49d713"
   },
   "outputs": [],
   "source": [
    "train_ds, validation_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-23T12:04:47.323035Z",
     "iopub.status.busy": "2022-12-23T12:04:47.322585Z",
     "iopub.status.idle": "2022-12-23T12:04:47.333326Z",
     "shell.execute_reply": "2022-12-23T12:04:47.332416Z",
     "shell.execute_reply.started": "2022-12-23T12:04:47.323001Z"
    },
    "id": "qWNTNqWpfUj1"
   },
   "outputs": [],
   "source": [
    "def train_transforms(example_batch):\n",
    "  #qui possiamo randomizzare procedura di augmentation data\n",
    "    transforms = T.RandomApply(\n",
    "        [T.RandomHorizontalFlip(p=1),\n",
    "         T.RandomInvert(),\n",
    "         T.Grayscale(num_output_channels=3),\n",
    "         T.GaussianBlur(9, sigma=0.1),\n",
    "         T.RandomResizedCrop(512,scale=(0.5, 2.0)),\n",
    "         T.RandomResizedCrop(1024,scale=(0.5, 2.0))\n",
    "        ], p=0.25)\n",
    "    \n",
    "    feature_extractor=SegformerFeatureExtractor()\n",
    "\n",
    "    images = [transforms(x) for x in example_batch[\"image\"]]\n",
    "    labels = [x for x in example_batch[\"annotation\"]]\n",
    "    inputs = feature_extractor(images, labels)\n",
    "    return inputs\n",
    "\n",
    "\n",
    "def val_transforms(example_batch):\n",
    "    feature_extractor=SegformerFeatureExtractor()\n",
    "\n",
    "    images = [x for x in example_batch[\"image\"]]\n",
    "    labels = [x for x in example_batch[\"annotation\"]]\n",
    "    inputs = feature_extractor(images, labels)\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-23T12:04:47.334962Z",
     "iopub.status.busy": "2022-12-23T12:04:47.334535Z",
     "iopub.status.idle": "2022-12-23T12:04:47.346617Z",
     "shell.execute_reply": "2022-12-23T12:04:47.345797Z",
     "shell.execute_reply.started": "2022-12-23T12:04:47.334927Z"
    },
    "id": "j7jms0Wzfl8L"
   },
   "outputs": [],
   "source": [
    "train_ds.set_transform(train_transforms)\n",
    "test_ds.set_transform(val_transforms)\n",
    "validation_ds.set_transform(val_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-23T12:04:47.348261Z",
     "iopub.status.busy": "2022-12-23T12:04:47.347867Z",
     "iopub.status.idle": "2022-12-23T12:04:47.357349Z",
     "shell.execute_reply": "2022-12-23T12:04:47.356426Z",
     "shell.execute_reply.started": "2022-12-23T12:04:47.348226Z"
    },
    "id": "tYXcLpmohoPQ"
   },
   "outputs": [],
   "source": [
    "#print_gpu_utilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-23T12:04:47.359243Z",
     "iopub.status.busy": "2022-12-23T12:04:47.358906Z",
     "iopub.status.idle": "2022-12-23T12:04:47.670909Z",
     "shell.execute_reply": "2022-12-23T12:04:47.669939Z",
     "shell.execute_reply.started": "2022-12-23T12:04:47.359209Z"
    },
    "id": "4o_iyLu_oJKY",
    "outputId": "28ab45b0-2afe-4eae-db01-c20bd78dad27"
   },
   "outputs": [],
   "source": [
    "#Look at augmentation\n",
    "import matplotlib.pyplot as plt\n",
    "img=torch.tensor(train_ds[3]['pixel_values'][:])\n",
    "img=torch.permute(img, (1,2,0))\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "heiZtAaSJu7w"
   },
   "source": [
    "# ATTENTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1hb7ikpEOcyx"
   },
   "source": [
    "## Criss cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-23T12:04:47.672290Z",
     "iopub.status.busy": "2022-12-23T12:04:47.671950Z",
     "iopub.status.idle": "2022-12-23T12:04:47.688091Z",
     "shell.execute_reply": "2022-12-23T12:04:47.686956Z",
     "shell.execute_reply.started": "2022-12-23T12:04:47.672254Z"
    },
    "id": "oS-y0S0qqKum"
   },
   "outputs": [],
   "source": [
    "def NEG_INF_DIAG(n: int, device: torch.device) -> torch.Tensor:\n",
    "    \"\"\"Returns a diagonal matrix of size [n, n].\n",
    "\n",
    "    The diagonal are all \"-inf\". This is for avoiding calculating the\n",
    "    overlapped element in the Criss-Cross twice.\n",
    "    \"\"\"\n",
    "    return torch.diag(torch.tensor(float('-inf')).to(device).repeat(n), 0)\n",
    "\n",
    "\n",
    "class Scale(nn.Module):\n",
    "    \"\"\"A learnable scale parameter.\n",
    "\n",
    "    This layer scales the input by a learnable factor. It multiplies a\n",
    "    learnable scale parameter of shape (1,) with input of any shape.\n",
    "\n",
    "    Args:\n",
    "        scale (float): Initial value of scale factor. Default: 1.0\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, scale: float = 1.0):\n",
    "        super().__init__()\n",
    "        self.scale = nn.Parameter(torch.tensor(scale, dtype=torch.float))\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return x * self.scale\n",
    "\n",
    "\n",
    "class CrissCrossAttention(nn.Module):\n",
    "    \"\"\"Criss-Cross Attention Module.\n",
    "\n",
    "    .. note::\n",
    "        Before v1.3.13, we use a CUDA op. Since v1.3.13, we switch\n",
    "        to a pure PyTorch and equivalent implementation. For more\n",
    "        details, please refer to https://github.com/open-mmlab/mmcv/pull/1201.\n",
    "\n",
    "        Speed comparison for one forward pass\n",
    "\n",
    "        - Input size: [2,512,97,97]\n",
    "        - Device: 1 NVIDIA GeForce RTX 2080 Ti\n",
    "\n",
    "        +-----------------------+---------------+------------+---------------+\n",
    "        |                       |PyTorch version|CUDA version|Relative speed |\n",
    "        +=======================+===============+============+===============+\n",
    "        |with torch.no_grad()   |0.00554402 s   |0.0299619 s |5.4x           |\n",
    "        +-----------------------+---------------+------------+---------------+\n",
    "        |no with torch.no_grad()|0.00562803 s   |0.0301349 s |5.4x           |\n",
    "        +-----------------------+---------------+------------+---------------+\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): Channels of the input feature map.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels: int) -> None:\n",
    "        super().__init__()\n",
    "        self.query_conv = nn.Conv2d(in_channels, in_channels // 8, 1)\n",
    "        self.key_conv = nn.Conv2d(in_channels, in_channels // 8, 1)\n",
    "        self.value_conv = nn.Conv2d(in_channels, in_channels, 1)\n",
    "        self.gamma = Scale(0.)\n",
    "        self.in_channels = in_channels\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"forward function of Criss-Cross Attention.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input feature with the shape of\n",
    "                (batch_size, in_channels, height, width).\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output of the layer, with the shape of\n",
    "            (batch_size, in_channels, height, width)\n",
    "        \"\"\"\n",
    "        B, C, H, W = x.size()\n",
    "        query = self.query_conv(x)\n",
    "        key = self.key_conv(x)\n",
    "        value = self.value_conv(x)\n",
    "        energy_H = torch.einsum('bchw,bciw->bwhi', query, key) + NEG_INF_DIAG(\n",
    "            H, query.device)\n",
    "        energy_H = energy_H.transpose(1, 2)\n",
    "        energy_W = torch.einsum('bchw,bchj->bhwj', query, key)\n",
    "        attn = F.softmax(\n",
    "            torch.cat([energy_H, energy_W], dim=-1), dim=-1)  # [B,H,W,(H+W)]\n",
    "        out = torch.einsum('bciw,bhwi->bchw', value, attn[..., :H])\n",
    "        out += torch.einsum('bchj,bhwj->bchw', value, attn[..., H:])\n",
    "\n",
    "        out = self.gamma(out) + x\n",
    "        out = out.contiguous()\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        s = self.__class__.__name__\n",
    "        s += f'(in_channels={self.in_channels})'\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-23T12:04:47.690114Z",
     "iopub.status.busy": "2022-12-23T12:04:47.689748Z",
     "iopub.status.idle": "2022-12-23T12:04:47.701306Z",
     "shell.execute_reply": "2022-12-23T12:04:47.700456Z",
     "shell.execute_reply.started": "2022-12-23T12:04:47.690068Z"
    },
    "id": "BXCW1WGlJ86t"
   },
   "outputs": [],
   "source": [
    "class MySegformerAttention(nn.Module):\n",
    "    def __init__(self, config, hidden_size):\n",
    "        super().__init__()\n",
    "        self.cca = CrissCrossAttention(hidden_size)\n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self, hidden_states, height, width, output_attentions=False):\n",
    "       \n",
    "        #self_outputs = self.self(hidden_states, height, width, output_attentions)\n",
    "        #context_layer = self_outputs[0] # (1,16384,32) = (1,height*width,hidden_states.shape[-1] )\n",
    "\n",
    "        x=torch.reshape(hidden_states, (hidden_states.shape[0],hidden_states.shape[-1], height, width))\n",
    "        self_outputs= self.cca(x)\n",
    "        self_outputs=torch.reshape(self_outputs, (hidden_states.shape[0], height*width, hidden_states.shape[-1]))\n",
    "        self_outputs=(self_outputs,)\n",
    "\n",
    "\n",
    "        #attention_output = self.output(self_outputs[0], hidden_states) # (1,16384,32)\n",
    "        #outputs = (attention_output,) + self_outputs[1:]  # add attentions if we output them\n",
    "        #print('outputs: ', (outputs[0].shape)) (1,16384,32)\n",
    "       \n",
    "        return self_outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TK7XyPleOZLW"
   },
   "source": [
    "## sostituisci layer col nostro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-23T12:04:47.703366Z",
     "iopub.status.busy": "2022-12-23T12:04:47.702951Z",
     "iopub.status.idle": "2022-12-23T12:04:48.539488Z",
     "shell.execute_reply": "2022-12-23T12:04:48.538613Z",
     "shell.execute_reply.started": "2022-12-23T12:04:47.703330Z"
    },
    "id": "Trg4n1RzCxrt",
    "outputId": "b5899cbd-2f81-47ca-9948-cfb1e616c61e"
   },
   "outputs": [],
   "source": [
    "#RUN THIS CELL ONLY IF RUNNING FIRST EPOCH OF TRAINING, TO INITIALIZE THE MODEL,\n",
    "#IF WANT TO LOAD MODEL FROM SAVED STATE USE NEXT CELL\n",
    "\n",
    "#pretrained_model_name = \"nvidia/mit-b0\"\n",
    "#model = AutoModelForSemanticSegmentation.from_pretrained(pretrained_model_name)\n",
    "#config=model.config\n",
    "#\n",
    "#\n",
    "##aggiorneremo i pesi solo dei nuovi layer\n",
    "#for param in model.parameters(): \n",
    "#    param.requires_grad = False\n",
    "#\n",
    "#\n",
    "#def replace_att_layers(model):\n",
    "#  #replace attention layers with our attention layer\n",
    "#  sizes=[32,32,64,64,160,160,256,256]\n",
    "#  counter=0\n",
    "#\n",
    "#  for module in model.modules():\n",
    "#    classname = module.__class__.__name__\n",
    "#\n",
    "#    if 'SegformerLayer' in classname:\n",
    "#      module.attention=MySegformerAttention(config, sizes[counter])\n",
    "#      counter+=1\n",
    "#\n",
    "#  return model\n",
    "#\n",
    "#model=replace_att_layers(model)\n",
    "#\n",
    "#for param in model.decode_head.parameters():\n",
    "#  param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-23T12:04:48.541292Z",
     "iopub.status.busy": "2022-12-23T12:04:48.540855Z",
     "iopub.status.idle": "2022-12-23T12:04:51.470851Z",
     "shell.execute_reply": "2022-12-23T12:04:51.469511Z",
     "shell.execute_reply.started": "2022-12-23T12:04:48.541256Z"
    }
   },
   "outputs": [],
   "source": [
    "!mkdir '/kaggle/working/AML/'\n",
    "!mkdir '/kaggle/working/AML/models/'\n",
    "!mkdir '/kaggle/working/AML/models/very_final_train/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jYYmvEwXcD9n"
   },
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-23T12:04:51.473560Z",
     "iopub.status.busy": "2022-12-23T12:04:51.473135Z",
     "iopub.status.idle": "2022-12-23T12:04:51.478307Z",
     "shell.execute_reply": "2022-12-23T12:04:51.477223Z",
     "shell.execute_reply.started": "2022-12-23T12:04:51.473521Z"
    },
    "id": "je6fkqEKdZ5s"
   },
   "outputs": [],
   "source": [
    "#IN B0-FINAL TRAIN CI SONO LE RUN CON LE LOSS\n",
    "#IN FINAL TRAIN IL MODELLO CON I PARAMETRI PER EPOCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-23T12:04:51.497438Z",
     "iopub.status.busy": "2022-12-23T12:04:51.496298Z",
     "iopub.status.idle": "2022-12-23T12:04:51.882904Z",
     "shell.execute_reply": "2022-12-23T12:04:51.881858Z",
     "shell.execute_reply.started": "2022-12-23T12:04:51.497381Z"
    },
    "id": "nABUKFORfsY8",
    "outputId": "db6bc021-3f53-4ea6-b6b0-b978706904ee"
   },
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"mean_iou\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-23T12:04:51.884786Z",
     "iopub.status.busy": "2022-12-23T12:04:51.884369Z",
     "iopub.status.idle": "2022-12-23T12:04:51.894513Z",
     "shell.execute_reply": "2022-12-23T12:04:51.893133Z",
     "shell.execute_reply.started": "2022-12-23T12:04:51.884742Z"
    },
    "id": "pzw6SLPWfxCB"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    with torch.no_grad():\n",
    "        logits, labels = eval_pred\n",
    "        logits_tensor = torch.from_numpy(logits)\n",
    "        logits_tensor = nn.functional.interpolate(\n",
    "            logits_tensor,\n",
    "            size=labels.shape[-2:],\n",
    "            mode=\"bilinear\",\n",
    "            align_corners=False,\n",
    "        ).argmax(dim=1)\n",
    "\n",
    "        pred_labels = logits_tensor.detach().cpu().numpy()\n",
    "        metrics = metric.compute(\n",
    "            predictions=pred_labels,\n",
    "            references=labels,\n",
    "            num_labels=num_labels,\n",
    "            ignore_index=255,\n",
    "            reduce_labels=False,\n",
    "        )\n",
    "        for key, value in metrics.items():\n",
    "            if type(value) is np.ndarray:\n",
    "                metrics[key] = value.tolist()\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-23T12:04:51.896520Z",
     "iopub.status.busy": "2022-12-23T12:04:51.895932Z",
     "iopub.status.idle": "2022-12-23T12:04:51.907743Z",
     "shell.execute_reply": "2022-12-23T12:04:51.906634Z",
     "shell.execute_reply.started": "2022-12-23T12:04:51.896485Z"
    },
    "id": "72GeQqPx__ne",
    "outputId": "148abdcd-9583-4d53-9da5-4d89a87d5337"
   },
   "outputs": [],
   "source": [
    "print_gpu_utilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-23T12:04:51.913908Z",
     "iopub.status.busy": "2022-12-23T12:04:51.913631Z",
     "iopub.status.idle": "2022-12-23T12:05:45.139145Z",
     "shell.execute_reply": "2022-12-23T12:05:45.137466Z",
     "shell.execute_reply.started": "2022-12-23T12:04:51.913884Z"
    },
    "id": "LseWuIIZN4Dl",
    "outputId": "ceb7c595-2433-4d94-de23-5b4517d6dffa"
   },
   "outputs": [],
   "source": [
    "#PER TRAIN SU KAGGLE ALMENO SALVIAMO A OGNI EPOCH\n",
    "path='/kaggle/working/AML/models/very_final_train/'\n",
    "from_epoch='epoch6' \n",
    "model=torch.load('/kaggle/input/epoch6/epoch6')\n",
    "for i in range(4):\n",
    "    epochs=('epoch{}').format(int(from_epoch[5:])+i+1)\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "    #auto_find_batch_size = True,\n",
    "    per_device_train_batch_size = 1,\n",
    "    per_device_eval_batch_size = 1,\n",
    "    gradient_accumulation_steps = 4,\n",
    "    evaluation_strategy = 'epoch',\n",
    "    eval_accumulation_steps=1, # MAY CHANGE IT\n",
    "    optim = 'adafactor',\n",
    "    output_dir=\"/kaggle/working/AML/models/b0_very_final_train/\"+epochs,\n",
    "    learning_rate=6e-5,\n",
    "    num_train_epochs=1,\n",
    "    save_strategy=\"epoch\",\n",
    "    #eval_steps=1,\n",
    "    remove_unused_columns=False,\n",
    "    debug = 'underflow_overflow',\n",
    "    prediction_loss_only = True, \n",
    "    log_level = 'critical',\n",
    "    logging_strategy = 'epoch',\n",
    "    #fp16_full_eval = True,\n",
    "    #dataloader_num_workers = 2\n",
    "    load_best_model_at_end = False\n",
    "    #, gradient_checkpointing = True\n",
    "    )\n",
    "    \n",
    "    trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=validation_ds,\n",
    "    compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    results = trainer.train() \n",
    "    torch.save(model, path+epochs)\n",
    "    print(('finished {}').format(epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-12-23T12:05:45.140437Z",
     "iopub.status.idle": "2022-12-23T12:05:45.141316Z",
     "shell.execute_reply": "2022-12-23T12:05:45.141072Z",
     "shell.execute_reply.started": "2022-12-23T12:05:45.141045Z"
    }
   },
   "outputs": [],
   "source": [
    "shutil.make_archive('AML', 'zip', '/kaggle/working/AML/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ccV4BhwsMiRD"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
